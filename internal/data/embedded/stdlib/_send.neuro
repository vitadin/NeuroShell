%% Description: Seamless send implementation leveraging variable service and auto-client creation
%% Usage: \send Hello, how are you?
%% Assumes user has activated a model first (seamless "Model â†’ Chat" workflow)
%% 
%% Workflow:
%% 1. Ensure active session (create if needed)
%% 2. Add user message to session  
%% 3. Ensure active model (create default if needed)
%% 4. Get client (leverages auto-creation from model commands)
%% 5. Make LLM call
%% 6. Add assistant response and display

%% Step 1: Ensure active session - create if session-activate returns empty
\silent \session-activate
\silent \if-not[condition="${_session_id}"] \session-new

%% Step 2: Add user message to session
\silent \session-add-usermsg[session=${_session_id}] ${_1}

%% Step 3: Ensure active model - create default if no active model
\silent \get[#active_model_name]
\silent \if-not[condition="${#active_model_name}"] \model-new[catalog_id=O4M] default_model

%% Step 4: Get client using active model's provider (auto-created by model commands via stack service)
\silent \get[#active_model_provider]
\silent \llm-client-get[provider=${#active_model_provider}]

%% Step 5: Make LLM call using all components
\silent \llm-call[client_id=${_client_id}, session_id=${_session_id}]

%% Step 6: Add assistant response to session and display
\silent \session-add-assistantmsg[session=${_session_id}] ${#llm_response}
\silent \set[1="${#llm_response}"]
\render-markdown ${#llm_response}